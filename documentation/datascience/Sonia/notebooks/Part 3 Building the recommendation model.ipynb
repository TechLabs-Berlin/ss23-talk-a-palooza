{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "7274138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.spatial\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import hamming, pdist, squareform\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "ba6e221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"wbmasterf.parquet\")\n",
    "df[\"ageg\"] = pd.to_numeric(df[\"ageg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97f03e0",
   "metadata": {},
   "source": [
    "# Part 3: Building the recommendation model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1928afe",
   "metadata": {},
   "source": [
    "**Collaborative filtering**\n",
    "\n",
    "We have 3 options:\n",
    "\n",
    "- **User-based filtering:** find users with similar interaction patterns as our target user and then recommend items that similar users have interacted with to our target user.\n",
    "<br/>\n",
    "\n",
    "- **Item-based filtering:** identify items that are similar to the ones our target users has interacted with and then recommend to our target user.\n",
    "<br/>\n",
    "\n",
    "- A **hybrid** of the two\n",
    "<br/>\n",
    "\n",
    "\n",
    "We are building a hybrid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb098436",
   "metadata": {},
   "source": [
    "## **1. User-based similarities**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d8338",
   "metadata": {},
   "source": [
    "Create a matrix with binary information on user interactions. Rows represent users, columns represent items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "d773888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = df.pivot(index=\"child_id\", columns=\"item_id\", values=\"value\")\n",
    "\n",
    "#The order of the items gets jumbled up, so sort them again from 1 to 680\n",
    "itemsorted = sorted(user_item_matrix.columns, key=lambda x: int(x.split(\"_\")[1]))\n",
    "user_item_matrix = user_item_matrix[itemsorted]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12da6c1",
   "metadata": {},
   "source": [
    "Adjust item IDs to match python indices. We now have IDs from 0 to 679 instead of 1 to 680."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "b6bb5393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract 1 from all item IDs in the user_item_matrix columns\n",
    "user_item_matrix.columns = [f\"item_{int(col.split('_')[1]) - 1}\" if col.startswith(\"item_\") else col for col in user_item_matrix.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a11356",
   "metadata": {},
   "source": [
    "Input a test user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "1088f534",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_age_group = 5 \n",
    "target_sex = \"Male\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605711a8",
   "metadata": {},
   "source": [
    "Our EDA revealed that user characteristics, such as **`ageg`** and **`sex`**, have a big influence on user/child vocabulary. Segment our data in order to match the users in our database with our hypothetical target user.\n",
    "\n",
    "UX wants users to be able to opt to not share sex/gender information. If the user input for sex is passed on as `None`, all age-matched users are included, regardless of their sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "87848c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter our df so that it only includes information of age-matched users\n",
    "filtered_users = df[df[\"ageg\"] == target_age_group]\n",
    "\n",
    "# Only filter when sex input is not NA\n",
    "if target_sex != \"None\":\n",
    "    filtered_users = filtered_users[filtered_users[\"sex\"].str.lower() == target_sex.lower()]\n",
    "\n",
    "# Extract the IDs of the filtered users\n",
    "filtered_user_ids = filtered_users[\"child_id\"].unique()\n",
    "\n",
    "# Create a boolean mask to filter user information for the demographically matched users\n",
    "user_filter_mask = user_item_matrix.index.isin(filtered_user_ids)\n",
    "\n",
    "# Apply the user filter to our \"master\" matrix\n",
    "target_matrix = user_item_matrix[user_filter_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705668be",
   "metadata": {},
   "source": [
    "Now we start working with our target user's interaction history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "ad13d6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_interactions = np.zeros(680)\n",
    "user_interactions[[0,1]] = 1\n",
    "\n",
    "# Optionally, use one of the kids from our df\n",
    "# test = df[df[\"child_id\"] == 1][\"value\"]\n",
    "# interacted_items = test\n",
    "# user_interactions[interacted_items == 1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76bf90b",
   "metadata": {},
   "source": [
    "## **2. Item-based similarities**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70162f0a",
   "metadata": {},
   "source": [
    "We also want to take item similarity into account, so we need to create an item similarity matrix (or rather *dissimilarity*, since we are working with Jaccard's *distance*). Higher scores indicate less similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62530c4",
   "metadata": {},
   "source": [
    "Transpose the matrix. Rows now represent items and columns represent users. Then create a (dis)similarity matrix for the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "d1934baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_item_matrix = target_matrix.T\n",
    "itemsim = (scipy.spatial.distance.cdist(target_item_matrix.values, target_item_matrix.values, metric=\"jaccard\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac35b4e",
   "metadata": {},
   "source": [
    "Initialize the nearest neighbors model. We opt for Jaccard's distance, a simple metric suitable for binary data. We fit the model to the **filtered** user-item interaction matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "cfdb9b54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;jaccard&#x27;, n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;jaccard&#x27;, n_neighbors=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='jaccard', n_neighbors=1)"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = NearestNeighbors(n_neighbors=1, metric=\"jaccard\", algorithm=\"brute\")\n",
    "knn.fit(target_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e4b56a",
   "metadata": {},
   "source": [
    "the process:\n",
    "\n",
    "- Neighbours are identified, and their distances and indices are calculated\n",
    "- The interaction history of these neighbours is collected\n",
    "- Neighbour items that the user has already interacted with are dropped\n",
    "- Item scores for the remaining neighbour items are calculated (for each neighbour item, the score is the mean distance of the respective item to all of the items the user has interacted with)\n",
    "- These scores (weighted) are then combined with the distance score (weighted) of the neighbour whose interaction history they come from. For double items, only the smallest (best) score is taken into consideration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "5812258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendations_model(user_interactions):\n",
    "    distance, neighbor_indices = knn.kneighbors([user_interactions])\n",
    "\n",
    "    user_based_recommendations = []\n",
    "    for neighbor_index in neighbor_indices[0]:\n",
    "        neighbor_interactions = target_matrix.iloc[neighbor_index] \n",
    "                                # change target_matrix to user_item_matrix to drop segmentation\n",
    "        \n",
    "        user_based_recommendations.extend([int(item.split('_')[1]) for item in neighbor_interactions[neighbor_interactions == 1].index])\n",
    "\n",
    "    user_based_recommendations = [item for item in user_based_recommendations if user_interactions[item] == 0]\n",
    "    user_based_recommendations = list(set(user_based_recommendations))\n",
    "\n",
    "    item_scores = {\n",
    "        item_id: sum(\n",
    "            itemsim[item_id, user_interaction]\n",
    "            for user_interaction, interaction_value in enumerate(user_interactions)\n",
    "            if interaction_value == 1\n",
    "        ) / sum(user_interactions)\n",
    "        for item_id in user_based_recommendations\n",
    "    }\n",
    "\n",
    "    final_scores = {\n",
    "        item_id: combined_score\n",
    "        for item_id, neighbor_interaction in zip(item_scores.keys(), neighbor_interactions)\n",
    "        for combined_score in [(distance * user_weight + item_scores[item_id] * item_weight)]\n",
    "        if item_id not in combined_score or combined_score < final_scores[item_id]\n",
    "    }\n",
    "\n",
    "    final_scores = {key: np.min(value) for key, value in final_scores.items()}\n",
    "    final_scores = {key+1: value for key, value in final_scores.items()}\n",
    "\n",
    "\n",
    "    for item_id, score in final_scores.items():\n",
    "        if item_id in wordsz.index:\n",
    "            item_definition = wordsz.loc[item_id, \"word\"]\n",
    "            wbi = wordsz.loc[item_id, \"wordBankId\"]\n",
    "            \n",
    "    return final_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29d885e",
   "metadata": {},
   "source": [
    "Define the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "9414486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_weight = 0.3    # data already segmented, so lower weight for users\n",
    "item_weight = 1 - user_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b714b4f",
   "metadata": {},
   "source": [
    "Run the function: output is a dictionary, keys represent item_ids and values are distance scores, ranging from 0 to 1. Lower values indicate higher recommendation priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "ae016d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sonia/anaconda3/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sonia/anaconda3/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:2181: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{356: 0.3564465408805031,\n",
       " 5: 0.35574726083971053,\n",
       " 6: 0.34701047349700465,\n",
       " 389: 0.35951327433628316,\n",
       " 361: 0.3783078880407124,\n",
       " 204: 0.4299597478591236,\n",
       " 366: 0.35556603773584905,\n",
       " 400: 0.37088104325699744,\n",
       " 187: 0.39578266104756166,\n",
       " 348: 0.36100727702954566}"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_model(user_interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f1de35",
   "metadata": {},
   "source": [
    "## Final thoughts:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abced0f",
   "metadata": {},
   "source": [
    "<span style=\"background-color:red;color:white;padding:5px;\">**Problem:**</span>\n",
    "\n",
    "It seems a bit redundant to calculate both user-based similarity **and** segment our data based on the demographics of the target user\n",
    "\n",
    "<span style=\"background-color:green;color:white;padding:5px;\">**Solution:**</span>\n",
    "\n",
    "Drop the data segmentation. In the final model (used in API) segmentation was dropped by training our knn on our complete dataset and then serializing it (**`mod.pkl`**).\n",
    "\n",
    "<span style=\"background-color:red;color:white;padding:5px;\">**Problem:**</span>\n",
    "\n",
    "Since we will not have complete information on which items the target user has already interacted with (i.e. the words the child has already learned) for our prototype (not all words will be included in assessment), it is likely that many of the recommended items will be words that the user has actually already interacted with, especially since recommended items tend to be \"popular\" items. An idea would be to recommend not only items identified as most similar, but add some low-similarity items into the list of the recommendations. The issue here is that these words will likely not be age-appropriate for especially younger users, so this is not an ideal solution. \n",
    "\n",
    "<span style=\"background-color:red;color:white;padding:5px;\">**Problem:**</span>\n",
    "\n",
    "How will an extreme case of a user who has not interaced with **any** items impact our model?\n",
    "\n",
    "Looking at the wordbank data, it seems very unlikely that we will encounter a child who has learned 0 of the 680 possible words. However, our MVP will only be able to collect information for a limited number of items (40), which increases the likelihood of receiving an input filled with 0's.\n",
    "\n",
    "- **User-based similarities:** The metric used in our **`knn`** (jaccard) measures asymmetric binary attributes. The distances to all possible neighbours will therefore be 1, since their respective jaccard similarities will always be 0. However, the model will still identify neighbours (I am assuming that they are chosen randomly), so this will not stop an output from being generated.\n",
    "<br/>\n",
    "\n",
    "- **Item-based similarities:** The nature of how **`item_scores`** is calculated requires **`user_interactions`** to contain `1`'s. If not, it will just return a list of NA's, which will then impact the calculations in **`final_scores`**. No usable output will be generated.\n",
    "\n",
    "<span style=\"background-color:green;color:white;padding:5px;\">**Solution:**</span>\n",
    "\n",
    "Code designed to handle this kind of extreme case could be built into **`item_scores`** (for example, giving each item a score of `0` instead of `NA`, or dropping the calculation of these scores), but recommendations would still be generated completely randomly. Instead, the user could be provided with a list of items that are generally popular for their age group and sex, no model necessary. Additionally, assessment items should be chosen carefully and tailored to each individual user's characteristics (age/sex) to ensure that some of the presented words will be ones that thes user has already learned.\n",
    "\n",
    "<span style=\"background-color:red;color:white;padding:5px;\">**Problem:**</span>\n",
    "\n",
    "Evaluating the model will be tricky, since we cannot collect new data and are also working with binary data.\n",
    "\n",
    "<span style=\"background-color:green;color:white;padding:5px;\">**Solution:**</span>\n",
    "\n",
    "- Now that the data segmentation has been dropped, we can evaluate our user-based similarities by investigating the demographic characteristics of the identified neighbours. Will the \"nearest neighbours\" be of the same age and gender as our target user?\n",
    "<br/>\n",
    "\n",
    "\n",
    "- Additionally, we can evaluate the model on its tendency to recommend items that the user has already learned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab68d044",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd655ac",
   "metadata": {},
   "source": [
    "code for API result formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7997db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsz = pd.read_parquet(\"words.parquet\")\n",
    "word_mapping = dict(zip(wordsz[\"wordBankId\"], wordsz.index))\n",
    "\n",
    "formatted_final_scores = []\n",
    "\n",
    "for item_id, score in final_scores.items():\n",
    "    if item_id in wordsz.index:\n",
    "        item_definition = wordsz.loc[item_id, \"word\"]\n",
    "        wbi = wordsz.loc[item_id, \"wordBankId\"]\n",
    "\n",
    "        formatted_item = {\n",
    "            \"name\": item_definition,\n",
    "            \"priority\": score,\n",
    "            \"wordBankId\": wbi\n",
    "        }\n",
    "\n",
    "        formatted_final_scores.append(formatted_item)\n",
    "        \n",
    "formatted_final_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
